{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FinalID3 import *\n",
    "import seaborn as sns\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFTreeNumber =100\n",
    "RFDecisionTrees = []\n",
    "RFPredictedList = []\n",
    "targetValue = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n",
    "    ax1.grid(True)\n",
    "    plt.title('Abalone Feature Correlation')\n",
    "    labels=[list(df)]\n",
    "    ax1.set_xticklabels(labels,fontsize=6)\n",
    "    ax1.set_yticklabels(labels,fontsize=6)\n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    fig.colorbar(cax, ticks=[.75,.8,.85,.90,.95,1])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key= lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pylab as plt\n",
    "################################################################################################################\n",
    "############################ Global Initialization #############################################################\n",
    "targetAttribute = 'Poisonous/Edible'\n",
    "targetValue = []\n",
    "predictedList= []\n",
    "minimalGainThreshold = 1e-6\n",
    "defaultTargetValue = 'p'\n",
    "rawDataSet = 'MushroomDataSet_Before_PreProcessing.xlsx'\n",
    "processedDataSet = 'MushroomDataSet_After_PreProcessing.xlsx'\n",
    "columnToProcess = 'stalk-root'\n",
    "res = {}\n",
    "################################################################################################################\n",
    "################################### Finding the set of Target Value ############################################\n",
    "def initializeList(data):\n",
    "    groupedData = data.groupby([targetAttribute]).groups.keys()\n",
    "    return groupedData\n",
    "################################################################################################################\n",
    "################################## Creating the Tree Recursively ###############################################\n",
    "def createTree(df):\n",
    "    x = df.drop(labels=targetAttribute, axis=1)\n",
    "    y = df[targetAttribute] \n",
    "    ##Returning the original Set if no further split can be made######## \n",
    "    if len(y) == 0:\n",
    "        return y\n",
    "\n",
    "    if trueSet(y):\n",
    "        return set(y).pop()\n",
    "    \n",
    "    ##Finding the attribute which gives maximal information#############\n",
    "    \n",
    "    maxGainAttr,maxInfoGain = calcInforGainForEachAtrribute(df)\n",
    "##If the information gain is less than the threshold set we classify as 'Poisonous' instead of saying it edible##\n",
    "    if((maxGainAttr== None) and (maxInfoGain == None)):\n",
    "        return defaultTargetValue\n",
    "##################################################################################################################\n",
    "##### If there is an information gain we recursively do splits ##################################################\n",
    "    sets = df.groupby(maxGainAttr)\n",
    "    for k, v in sets:\n",
    "        res[\"%s = %s\" % (maxGainAttr, k)] = createTree(v)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcInforGainForEachAtrribute(df):\n",
    "    # return maximum info gain\n",
    "    maxInfoGain =0;\n",
    "    infoGainDict = {}\n",
    "    attributes = list(df)\n",
    "    totalEntropy = entropy(df)\n",
    "\n",
    "    for att in attributes:\n",
    "        #don't calculate gain for target attribute\n",
    "        if (att ==targetAttribute ):\n",
    "            continue\n",
    "        grouped_data = df.groupby([att], as_index=False)\n",
    "        totalRows = len(df)\n",
    "        subEntropy = 0\n",
    "        for key, value in grouped_data:\n",
    "            eachGroupRows = len(value)\n",
    "            S = entropy(value)\n",
    "            #calculate |Sv/S|\n",
    "            valEntrpy = eachGroupRows / totalRows\n",
    "            #calculate |Sv/S|*Entropy(Sv)\n",
    "            subEntropy = subEntropy + valEntrpy * S\n",
    "        individualEntrpyGain = totalEntropy - subEntropy\n",
    "        infoGainDict[att] = individualEntrpyGain\n",
    "        if (individualEntrpyGain > maxInfoGain):\n",
    "            maxInfoGain = individualEntrpyGain\n",
    "            maxGainAttr = att;\n",
    "    # If there's no gain at all, nothing has to be done, just return the original set\n",
    "    if (maxInfoGain < minimalGainThreshold):\n",
    "        return None, None\n",
    "    else:\n",
    "        return maxGainAttr,maxInfoGain\n",
    "##################################################################################################################\n",
    "######################### Evaluating if a Pure Set is reached ?################################################### \n",
    "def trueSet(s):\n",
    "    return len(set(s)) == 1\n",
    "###################################################################################################################\n",
    "########################### Entropy Calculator ######################################################################\n",
    "def entropy(df):\n",
    "    #target unique value calculation in form of dictionary \n",
    "    targetDict = pd.value_counts(df[targetAttribute]).to_dict()\n",
    "    dfLength =len(df) \n",
    "    totalEntropy = 0\n",
    "    for key, val in targetDict.items():\n",
    "        multipleVal = val/dfLength\n",
    "        totalEntropy += multipleVal * math.log2(multipleVal)\n",
    "    return 0-totalEntropy\n",
    "##################################################################################################################\n",
    "########################## Evaluating the Test Data by Passing the Learned tree and Test Data as Parameters #####\n",
    "\n",
    "##################################################################################################################\n",
    "########################### Printing the Confusion Matrix #######################################################\n",
    "def printMatrix(y_test,predictedList,labels):\n",
    "    cm = confusion_matrix(y_test, pd.Series(predictedList), labels)\n",
    "    print(cm)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictTarget(targetDict,test):\n",
    "    for k,v in targetDict.items():\n",
    "        keyList = k.split('=')\n",
    "        col = keyList[0].strip()\n",
    "        val = keyList[1].strip()\n",
    "        if(test[col].iloc[0] == val):\n",
    "            if k in targetDict:\n",
    "                temp = targetDict.get(k)\n",
    "                if(type(temp) == dict):\n",
    "                    return predictTarget(v,test)\n",
    "                else:\n",
    "                    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictTarget1(targetDict,test):\n",
    "    t1 =[]\n",
    "    t2 =[]\n",
    "    for k,v in targetDict.items():\n",
    "        keyList = k.split('=')\n",
    "        col = keyList[0].strip()\n",
    "        val = keyList[1].strip()\n",
    "        t1.append(val)\n",
    "        t2.append(v)\n",
    "    \n",
    "    searchVal = test[col].iloc[0]\n",
    "    if(searchVal in t1 ):\n",
    "        index = t1.index(searchVal)\n",
    "        finalVal = t2[index]\n",
    "        \n",
    "        if(type(finalVal) == dict):\n",
    "            return predictTarget1(finalVal,test)\n",
    "        else:\n",
    "            return finalVal    \n",
    "    else:\n",
    "        return defaultTargetValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictTarget2(targetDict,test):\n",
    "    t1 =[]\n",
    "    t2 =[]\n",
    "    for k,v in targetDict.items():\n",
    "        keyList = k.split('=')\n",
    "        col = keyList[0].strip()\n",
    "        val = keyList[1].strip()\n",
    "        t1.append(val)\n",
    "        t2.append(v)\n",
    "    \n",
    "    searchVal = test[col].iloc[0]\n",
    "    if(searchVal in t1 ):\n",
    "        index = t1.index(searchVal)\n",
    "        finalVal = t2[index]\n",
    "        \n",
    "        return finalVal    \n",
    "    else:\n",
    "        return defaultTargetValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depth(d, level=1):\n",
    "    if not isinstance(d, dict) or not d:\n",
    "        return level\n",
    "    return max(depth(d[k], level + 1) for k in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Poisonous/Edible', 'cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "(8124, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4094ce8f470c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     '''\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-4094ce8f470c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtargetDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"depth :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     '''\n",
      "\u001b[0;32m<ipython-input-31-a8424026a51b>\u001b[0m in \u001b[0;36mdepth\u001b[0;34m(d, level)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-a8424026a51b>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "... last 2 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-31-a8424026a51b>\u001b[0m in \u001b[0;36mdepth\u001b[0;34m(d, level)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datasetAfterProcessing = pd.read_excel(processedDataSet)\n",
    "    X = datasetAfterProcessing.drop(labels=targetAttribute, axis=1)\n",
    "    y = datasetAfterProcessing[targetAttribute]\n",
    "    print(list(datasetAfterProcessing))\n",
    "    print(datasetAfterProcessing.shape)\n",
    "    #results = datasetAfterProcessing.corr()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)\n",
    "    X_train[targetAttribute] = y_train\n",
    "    targetValue = initializeList(datasetAfterProcessing)\n",
    "    dfLength = len(X)\n",
    "    \n",
    "    #Mashroom has total length of training data = 6499\n",
    "    \n",
    "    #devide total training data by RFTreeNumber\n",
    "    myset = set()\n",
    "    #temp = []\n",
    "    RFDecisionTrees =[]\n",
    "    '''\n",
    "    X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_train, y_train, test_size=0.2, random_state=40)\n",
    "    X_sub_train[targetAttribute] = y_sub_train\n",
    "        \n",
    "    #for each chunk create decision tree and store it in RFDecisionTrees\n",
    "    targetDict = createTree(X_sub_train)\n",
    "    \n",
    "    print(\"depth :\",depth(targetDict))\n",
    "    '''\n",
    "    \n",
    "    for i in range(40,70):\n",
    "        #creating \n",
    "        #random_state = random.randint(0,100)\n",
    "        X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_train, y_train, test_size=0.2, random_state=i)\n",
    "        X_sub_train[targetAttribute] = y_sub_train\n",
    "        \n",
    "        #for each chunk create decision tree and store it in RFDecisionTrees\n",
    "        targetDict = createTree(X_sub_train)\n",
    "        #temp.append(str(targetDict))\n",
    "        RFDecisionTrees.append(targetDict)\n",
    "    \n",
    "    #myset = set(temp)\n",
    "    #print(\"len :\",len(myset))\n",
    "    \n",
    "    RFPredictedList =[]\n",
    "    #print(\"RFDecisionTrees :\",len(RFDecisionTrees))\n",
    "    for i in range(0,len(X_test)):\n",
    "        tempPredictionList =[]\n",
    "        curr = X_test.iloc[[i]]\n",
    "        for tree in RFDecisionTrees:\n",
    "            \n",
    "            myTree = tree\n",
    "            ansFlag = True\n",
    "            while(ansFlag):\n",
    "                tempPredictedval = predictTarget2(myTree,curr)\n",
    "                if(type(tempPredictedval) == dict):\n",
    "                    myTree = tempPredictedval\n",
    "                else:\n",
    "                    ansFlag = False\n",
    "            \n",
    "            #predictedVal = predictTarget(tree,X_test.iloc[[i]])\n",
    "            tempPredictionList.append(tempPredictedval)\n",
    "        \n",
    "        print(\"length :\",len(tempPredictionList),\"LIST :\",set(tempPredictionList),\" most_common(tempPredictionList):\",most_common(tempPredictionList))\n",
    "        RFPredictedList.append(set(most_common(tempPredictionList)).pop())\n",
    "    \n",
    "    print(\"y_test: \",len(y_test))\n",
    "    print(\"RFPredictedList: \",len(RFPredictedList))\n",
    "    printMatrix(y_test,RFPredictedList,list(targetValue))\n",
    "    \n",
    "   \n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
